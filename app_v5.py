#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒªã‚¹ãƒˆèª¿æŸ»ã‚·ã‚¹ãƒ†ãƒ  GUI v5.0
=====================================
v3ï¼ˆåº—èˆ—èª¿æŸ»ï¼‰ã¨v4ï¼ˆæ­£èª¤ãƒã‚§ãƒƒã‚¯ï¼‰ã‚’çµ±åˆã€‚
AIèª¿æŸ»ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã€ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨ã—ã¦ä½µå­˜ã€‚

ã€æ©Ÿèƒ½ã€‘
- ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒªã‚¹ãƒˆæ­£èª¤ãƒã‚§ãƒƒã‚¯ï¼ˆv4ã‹ã‚‰ç¶™æ‰¿ï¼‰
- åº—èˆ—ãƒ»æ•™å®¤èª¿æŸ»ï¼ˆAIèª¿æŸ» æ¨å¥¨ + ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

ã€èª¿æŸ»ãƒ¢ãƒ¼ãƒ‰ã€‘
- AIèª¿æŸ»ï¼ˆæ¨å¥¨ï¼‰: LLMã«ã‚ˆã‚‹Webæ¤œç´¢ãƒ™ãƒ¼ã‚¹
- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°: ã‚µã‚¤ãƒˆç›´æ¥ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°
- ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰: AIèª¿æŸ» â†’ ä½ä¿¡é ¼åº¦æ™‚ã«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è£œå®Œ

ã€ä½¿ç”¨æ–¹æ³•ã€‘
```bash
streamlit run app_v5.py
```
"""

import asyncio
import io
import os
import sys
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Optional

import pandas as pd
import streamlit as st

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))

from core.async_helpers import run_async
from core.excel_handler import (
    ExcelHandler,
    ValidationReportExporter,
    StoreInvestigationExporter,
    PlayerData,
)
from core.llm_client import LLMClient, get_available_providers, get_default_client
from investigators.base import (
    AlertLevel,
    ChangeType,
    ValidationStatus,
    ValidationResult,
    StoreInvestigationResult,
)
from investigators.player_validator import PlayerValidator
from investigators.store_investigator import StoreInvestigator, InvestigationMode
from ui.attribute_tab import render_attribute_tab
from ui.newcomer_tab import render_newcomer_tab
from ui.workflow_tab import render_workflow_tab

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒªã‚¹ãƒˆèª¿æŸ»ã‚·ã‚¹ãƒ†ãƒ  v6.0",
    page_icon="ğŸ”",
    layout="wide",
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    /* ã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒƒã‚¸ */
    .alert-critical {
        background-color: #FF6B6B;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-weight: bold;
    }
    .alert-warning {
        background-color: #FFD93D;
        color: #333;
        padding: 4px 12px;
        border-radius: 20px;
        font-weight: bold;
    }
    .alert-info {
        background-color: #6BCB77;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-weight: bold;
    }
    .alert-ok {
        background-color: #4ECDC4;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-weight: bold;
    }
    .alert-uncertain {
        background-color: #FFA500;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-weight: bold;
    }

    /* ã‚µãƒãƒªãƒ¼ã‚«ãƒ¼ãƒ‰ */
    .summary-card {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
        border-left: 5px solid #4A90D9;
    }

    /* é€²æ—ãƒ­ã‚° */
    .progress-log {
        background-color: #1a1a2e;
        color: #16f4d0;
        padding: 15px;
        border-radius: 8px;
        font-family: 'Consolas', 'Monaco', monospace;
        font-size: 13px;
        max-height: 300px;
        overflow-y: auto;
    }

    /* è­¦å‘Šãƒœãƒƒã‚¯ã‚¹ */
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffc107;
        border-radius: 8px;
        padding: 15px;
        margin: 10px 0;
    }
    .warning-box h4 {
        color: #856404;
        margin-top: 0;
    }
    .warning-box ul {
        margin-bottom: 0;
        color: #856404;
    }

    /* çµæœãƒ†ãƒ¼ãƒ–ãƒ« */
    .result-table {
        font-size: 14px;
    }
</style>
""", unsafe_allow_html=True)


# ====================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
# ====================================
def init_session_state() -> None:
    """Streamlit ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    # æ­£èª¤ãƒã‚§ãƒƒã‚¯ç”¨
    if "players" not in st.session_state:
        st.session_state.players = []
    if "validation_results" not in st.session_state:
        st.session_state.validation_results = []

    # åº—èˆ—èª¿æŸ»ç”¨
    if "store_companies" not in st.session_state:
        st.session_state.store_companies = []
    if "store_results" not in st.session_state:
        st.session_state.store_results = []

    # å…±é€š
    if "progress_logs" not in st.session_state:
        st.session_state.progress_logs = []
    if "is_running" not in st.session_state:
        st.session_state.is_running = False


# ====================================
# APIåˆæœŸåŒ–
# ====================================
def init_apis() -> dict[str, bool]:
    """APIè¨­å®šã‚’åˆæœŸåŒ–ã—ã€åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’è¿”ã™"""
    from dotenv import load_dotenv
    load_dotenv(Path.home() / ".env.local", override=True)

    providers = get_available_providers()
    return providers


# ====================================
# æ­£èª¤ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
# ====================================
async def run_validation(
    players: list[PlayerData],
    industry: str,
    provider: str,
    progress_container,
    status_container,
) -> list[ValidationResult]:
    """æ­£èª¤ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""

    logs = []

    def on_progress(current: int, total: int, name: str):
        log_msg = f"[{current}/{total}] ãƒã‚§ãƒƒã‚¯ä¸­: {name}"
        logs.append(log_msg)
        log_text = "\n".join(logs[-15:])
        progress_container.markdown(
            f'<div class="progress-log">{log_text}</div>',
            unsafe_allow_html=True
        )

    status_container.info(f"ğŸ” {len(players)}ä»¶ã®ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")

    try:
        llm = LLMClient(provider=provider)
        validator = PlayerValidator(llm_client=llm)

        results = await validator.validate_batch(
            players,
            industry=industry,
            on_progress=on_progress,
            concurrency=2,
            delay_seconds=1.5,
        )

        status_container.success(f"âœ… ãƒã‚§ãƒƒã‚¯å®Œäº†: {len(results)}ä»¶")
        return results

    except Exception as e:
        status_container.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}")
        return []


# ====================================
# åº—èˆ—èª¿æŸ»å®Ÿè¡Œ
# ====================================
async def run_store_investigation(
    companies: list[dict],
    mode: InvestigationMode,
    provider: str,
    progress_container,
    status_container,
    ai_model: str = "sonar-pro",
) -> list[StoreInvestigationResult]:
    """åº—èˆ—èª¿æŸ»ã‚’å®Ÿè¡Œ

    Args:
        companies: èª¿æŸ»å¯¾è±¡ä¼æ¥­ãƒªã‚¹ãƒˆ
        mode: èª¿æŸ»ãƒ¢ãƒ¼ãƒ‰ï¼ˆAI / SCRAPING / HYBRIDï¼‰
        provider: LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆperplexity / geminiï¼‰
        progress_container: é€²æ—è¡¨ç¤ºç”¨Streamlitã‚³ãƒ³ãƒ†ãƒŠ
        status_container: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºç”¨Streamlitã‚³ãƒ³ãƒ†ãƒŠ
        ai_model: AIãƒ¢ãƒ‡ãƒ«ï¼ˆsonar-pro / sonar-deep-researchï¼‰
    """

    logs = []

    def on_progress(current: int, total: int, name: str):
        log_msg = f"[{current}/{total}] èª¿æŸ»ä¸­: {name}"
        logs.append(log_msg)
        log_text = "\n".join(logs[-15:])
        progress_container.markdown(
            f'<div class="progress-log">{log_text}</div>',
            unsafe_allow_html=True
        )

    model_label = "ç²¾å¯†" if ai_model == "sonar-deep-research" else "é«˜é€Ÿ"
    status_container.info(f"ğŸª {len(companies)}ä»¶ã®ä¼æ¥­ã‚’èª¿æŸ»ä¸­... (ãƒ¢ãƒ¼ãƒ‰: {model_label})")

    try:
        llm = LLMClient(provider=provider)
        investigator = StoreInvestigator(llm_client=llm, model=ai_model)

        results = await investigator.investigate_batch(
            companies,
            mode=mode,
            on_progress=on_progress,
            concurrency=2,
            delay_seconds=1.5,
        )

        status_container.success(f"âœ… èª¿æŸ»å®Œäº†: {len(results)}ä»¶")
        return results

    except Exception as e:
        status_container.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}")
        return []


# ====================================
# çµæœè¡¨ç¤ºï¼ˆæ­£èª¤ãƒã‚§ãƒƒã‚¯ï¼‰
# ====================================
def display_validation_summary(results: list[ValidationResult]):
    """æ­£èª¤ãƒã‚§ãƒƒã‚¯çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""

    alert_counts = {
        AlertLevel.CRITICAL: 0,
        AlertLevel.WARNING: 0,
        AlertLevel.INFO: 0,
        AlertLevel.OK: 0,
    }
    uncertain_count = 0

    for result in results:
        alert_counts[result.alert_level] = alert_counts.get(result.alert_level, 0) + 1
        if result.needs_manual_review:
            uncertain_count += 1

    st.markdown("### ğŸ“Š ãƒã‚§ãƒƒã‚¯çµæœã‚µãƒãƒªãƒ¼")

    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        st.metric("ğŸ”´ ç·Šæ€¥ï¼ˆæ’¤é€€ãƒ»çµ±åˆï¼‰", f"{alert_counts[AlertLevel.CRITICAL]}ä»¶")

    with col2:
        st.metric("ğŸŸ¡ è­¦å‘Šï¼ˆåç§°å¤‰æ›´ï¼‰", f"{alert_counts[AlertLevel.WARNING]}ä»¶")

    with col3:
        st.metric("ğŸŸ¢ æƒ…å ±ï¼ˆURLå¤‰æ›´ç­‰ï¼‰", f"{alert_counts[AlertLevel.INFO]}ä»¶")

    with col4:
        st.metric("âœ… å¤‰æ›´ãªã—", f"{alert_counts[AlertLevel.OK]}ä»¶")

    with col5:
        st.metric("âš ï¸ è¦ç¢ºèª", f"{uncertain_count}ä»¶")


def display_validation_table(results: list[ValidationResult]):
    """æ­£èª¤ãƒã‚§ãƒƒã‚¯çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º"""

    alert_order = {
        AlertLevel.CRITICAL: 0,
        AlertLevel.WARNING: 1,
        AlertLevel.INFO: 2,
        AlertLevel.OK: 3,
    }
    sorted_results = sorted(
        results,
        key=lambda r: (alert_order.get(r.alert_level, 4), not r.needs_manual_review)
    )

    data = []
    for result in sorted_results:
        data.append({
            "ã‚¢ãƒ©ãƒ¼ãƒˆ": result.alert_level.value,
            "ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼åï¼ˆå…ƒï¼‰": result.player_name_original,
            "ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼åï¼ˆç¾åœ¨ï¼‰": result.player_name_current,
            "å¤‰æ›´ã‚¿ã‚¤ãƒ—": result.change_type.value,
            "å¤‰æ›´å†…å®¹": " / ".join(result.change_details) if result.change_details else "-",
            "ä¿¡é ¼åº¦": f"{result.confidence * 100:.0f}%",
            "è¦ç¢ºèª": "âš ï¸" if result.needs_manual_review else "",
        })

    df = pd.DataFrame(data)

    st.dataframe(
        df,
        use_container_width=True,
        height=400,
        column_config={
            "ã‚¢ãƒ©ãƒ¼ãƒˆ": st.column_config.TextColumn("ã‚¢ãƒ©ãƒ¼ãƒˆ", width="small"),
            "ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼åï¼ˆå…ƒï¼‰": st.column_config.TextColumn("ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼åï¼ˆå…ƒï¼‰", width="medium"),
            "ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼åï¼ˆç¾åœ¨ï¼‰": st.column_config.TextColumn("ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼åï¼ˆç¾åœ¨ï¼‰", width="medium"),
            "å¤‰æ›´ã‚¿ã‚¤ãƒ—": st.column_config.TextColumn("å¤‰æ›´ã‚¿ã‚¤ãƒ—", width="small"),
            "å¤‰æ›´å†…å®¹": st.column_config.TextColumn("å¤‰æ›´å†…å®¹", width="large"),
            "ä¿¡é ¼åº¦": st.column_config.TextColumn("ä¿¡é ¼åº¦", width="small"),
            "è¦ç¢ºèª": st.column_config.TextColumn("è¦ç¢ºèª", width="small"),
        }
    )


# ====================================
# çµæœè¡¨ç¤ºï¼ˆåº—èˆ—èª¿æŸ»ï¼‰
# ====================================
def display_store_summary(results: list[StoreInvestigationResult]):
    """åº—èˆ—èª¿æŸ»çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""

    # Noneå¯¾ç­–: total_stores ã‚„ confidence ãŒ None ã®å ´åˆã«å‚™ãˆã‚‹
    total_stores = sum((r.total_stores or 0) for r in results)
    high_conf = sum(1 for r in results if (r.confidence or 0) >= 0.8)
    medium_conf = sum(1 for r in results if 0.5 <= (r.confidence or 0) < 0.8)
    low_conf = sum(1 for r in results if (r.confidence or 0) < 0.5)
    need_verify = sum(1 for r in results if r.needs_verification)

    st.markdown("### ğŸ“Š åº—èˆ—èª¿æŸ»çµæœã‚µãƒãƒªãƒ¼")

    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        st.metric("ç·åº—èˆ—æ•°", f"{total_stores:,}åº—èˆ—")

    with col2:
        st.metric("ğŸŸ¢ é«˜ä¿¡é ¼åº¦", f"{high_conf}ä»¶")

    with col3:
        st.metric("ğŸŸ¡ ä¸­ä¿¡é ¼åº¦", f"{medium_conf}ä»¶")

    with col4:
        st.metric("ğŸ”´ ä½ä¿¡é ¼åº¦", f"{low_conf}ä»¶")

    with col5:
        st.metric("âš ï¸ è¦ç¢ºèª", f"{need_verify}ä»¶")


def display_store_table(results: list[StoreInvestigationResult]):
    """åº—èˆ—èª¿æŸ»çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º"""

    # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆï¼ˆä½ã„é †ï¼‰ã€Noneå¯¾ç­–
    sorted_results = sorted(results, key=lambda r: (r.needs_verification, -(r.confidence or 0)))

    data = []
    for result in sorted_results:
        data.append({
            "ä¼æ¥­å": result.company_name,
            "åº—èˆ—æ•°": result.total_stores or 0,
            "ç›´å–¶åº—": result.direct_stores if result.direct_stores is not None else "-",
            "FCåº—": result.franchise_stores if result.franchise_stores is not None else "-",
            "èª¿æŸ»ãƒ¢ãƒ¼ãƒ‰": result.investigation_mode,
            "ä¿¡é ¼åº¦": f"{(result.confidence or 0) * 100:.0f}%",
            "è¦ç¢ºèª": "âš ï¸" if result.needs_verification else "",
            "ã‚½ãƒ¼ã‚¹URL": ", ".join(result.source_urls[:2]) if result.source_urls else "-",
        })

    df = pd.DataFrame(data)

    st.dataframe(
        df,
        use_container_width=True,
        height=400,
        column_config={
            "ä¼æ¥­å": st.column_config.TextColumn("ä¼æ¥­å", width="medium"),
            "åº—èˆ—æ•°": st.column_config.NumberColumn("åº—èˆ—æ•°", width="small"),
            "ç›´å–¶åº—": st.column_config.TextColumn("ç›´å–¶åº—", width="small"),
            "FCåº—": st.column_config.TextColumn("FCåº—", width="small"),
            "èª¿æŸ»ãƒ¢ãƒ¼ãƒ‰": st.column_config.TextColumn("èª¿æŸ»ãƒ¢ãƒ¼ãƒ‰", width="small"),
            "ä¿¡é ¼åº¦": st.column_config.TextColumn("ä¿¡é ¼åº¦", width="small"),
            "è¦ç¢ºèª": st.column_config.TextColumn("è¦ç¢ºèª", width="small"),
            "ã‚½ãƒ¼ã‚¹URL": st.column_config.TextColumn("ã‚½ãƒ¼ã‚¹URL", width="large"),
        }
    )


# ====================================
# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# ====================================
def export_validation_results(results: list[ValidationResult]) -> bytes:
    """æ­£èª¤ãƒã‚§ãƒƒã‚¯çµæœã‚’Excelã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""

    report_data = []
    for result in results:
        report_data.append({
            "ã‚¢ãƒ©ãƒ¼ãƒˆ": result.alert_level.value,
            "ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼åï¼ˆå…ƒï¼‰": result.player_name_original,
            "ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼åï¼ˆç¾åœ¨ï¼‰": result.player_name_current,
            "å¤‰æ›´ã‚¿ã‚¤ãƒ—": result.change_type.value,
            "å¤‰æ›´å†…å®¹": "\n".join(result.change_details) if result.change_details else "",
            "å…¬å¼URLï¼ˆå…ƒï¼‰": result.url_original,
            "å…¬å¼URLï¼ˆç¾åœ¨ï¼‰": result.url_current,
            "é‹å–¶ä¼šç¤¾ï¼ˆå…ƒï¼‰": result.company_name_original,
            "é‹å–¶ä¼šç¤¾ï¼ˆç¾åœ¨ï¼‰": result.company_name_current,
            "ä¿¡é ¼åº¦": f"{result.confidence * 100:.0f}%",
            "è¦ç¢ºèªãƒ•ãƒ©ã‚°": "TRUE" if result.needs_manual_review else "FALSE",
            "é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹": result.news_summary,
            "æƒ…å ±ã‚½ãƒ¼ã‚¹": "\n".join(result.source_urls) if result.source_urls else "",
            "ãƒã‚§ãƒƒã‚¯æ—¥æ™‚": result.checked_at.strftime("%Y-%m-%d %H:%M:%S") if result.checked_at else "",
        })

    df_report = pd.DataFrame(report_data)

    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        df_report.to_excel(writer, index=False, sheet_name="ãƒã‚§ãƒƒã‚¯çµæœ")

        worksheet = writer.sheets["ãƒã‚§ãƒƒã‚¯çµæœ"]
        for idx, col in enumerate(df_report.columns):
            max_length = max(
                df_report[col].astype(str).map(len).max(),
                len(col)
            ) + 2
            worksheet.column_dimensions[chr(65 + idx)].width = min(max_length, 50)

    return buffer.getvalue()


def export_store_results(results: list[StoreInvestigationResult]) -> bytes:
    """åº—èˆ—èª¿æŸ»çµæœã‚’Excelã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""

    buffer = io.BytesIO()

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    temp_path = Path(tempfile.gettempdir()) / "store_results_temp.xlsx"
    exporter = StoreInvestigationExporter(include_prefectures=True)
    exporter.export(results, temp_path)

    # ãƒã‚¤ãƒŠãƒªèª­ã¿è¾¼ã¿
    with open(temp_path, "rb") as f:
        buffer.write(f.read())

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    temp_path.unlink(missing_ok=True)

    return buffer.getvalue()


# ====================================
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ³¨æ„äº‹é …
# ====================================
def display_scraping_warning():
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã®æ³¨æ„äº‹é …ã‚’è¡¨ç¤º"""
    st.markdown("""
    <div class="warning-box">
    <h4>âš ï¸ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã®æ³¨æ„äº‹é …</h4>
    <ul>
        <li>å¯¾è±¡ã‚µã‚¤ãƒˆã®åˆ©ç”¨è¦ç´„ã‚’å¿…ãšã”ç¢ºèªãã ã•ã„</li>
        <li>robots.txt ã§ç¦æ­¢ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„</li>
        <li>æœ¬æ©Ÿèƒ½ã®ä½¿ç”¨ã«ã‚ˆã‚‹æ³•çš„å•é¡Œã¯åˆ©ç”¨è€…ã®è²¬ä»»ã¨ãªã‚Šã¾ã™</li>
        <li>ç¤¾å†…åˆ©ç”¨ã®ã¿ã‚’æ¨å¥¨ã—ã¾ã™ï¼ˆå¤–éƒ¨å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã¸ã®ä½¿ç”¨ã¯éæ¨å¥¨ï¼‰</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)


# ====================================
# ãƒ¡ã‚¤ãƒ³UI
# ====================================
def main():
    init_session_state()

    st.title("ğŸ” ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒªã‚¹ãƒˆèª¿æŸ»ã‚·ã‚¹ãƒ†ãƒ  v6.0")
    st.caption("æ­£èª¤ãƒã‚§ãƒƒã‚¯ + åº—èˆ—èª¿æŸ» + å±æ€§èª¿æŸ» + æ–°è¦å‚å…¥æ¤œå‡º + 3æ®µéšãƒã‚§ãƒƒã‚¯ | AIèª¿æŸ»ï¼ˆæ¨å¥¨ï¼‰")

    # ====================================
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    # ====================================
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")

        # APIçŠ¶æ…‹
        providers = init_apis()

        st.subheader("ğŸ”‘ APIæ¥ç¶š")
        if providers.get("perplexity"):
            st.success("âœ… Perplexity: æ¥ç¶šOK")
        else:
            st.warning("âš ï¸ Perplexity: æœªè¨­å®š")

        if providers.get("gemini"):
            st.success("âœ… Gemini: æ¥ç¶šOK")
        else:
            st.warning("âš ï¸ Gemini: æœªè¨­å®š")

        if not any(providers.values()):
            st.error("âŒ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            st.info("~/.env.local ã« PERPLEXITY_API_KEY ã¾ãŸã¯ GOOGLE_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„")
            st.stop()

        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠ
        available_providers = [k for k, v in providers.items() if v]
        provider = st.selectbox(
            "ä½¿ç”¨ã™ã‚‹LLM",
            available_providers,
            format_func=lambda x: "Perplexity (æ¨å¥¨)" if x == "perplexity" else "Gemini",
        )

        st.divider()

        # æ¥­ç•Œé¸æŠ
        st.subheader("ğŸ“‹ æ¥­ç•Œè¨­å®š")
        industry = st.selectbox(
            "å¯¾è±¡æ¥­ç•Œ",
            [
                "",
                "ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰",
                "å‹•ç”»é…ä¿¡ã‚µãƒ¼ãƒ“ã‚¹",
                "ä¸­å¤è»Šè²©å£²åº—",
                "å­¦ç¿’å¡¾ãƒ»äºˆå‚™æ ¡",
                "ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚¯ãƒ©ãƒ–",
                "é£²é£Ÿåº—",
                "å°å£²åº—",
                "ãã®ä»–",
            ],
            format_func=lambda x: "é¸æŠã—ã¦ãã ã•ã„" if x == "" else x,
        )

        if industry == "ãã®ä»–":
            industry = st.text_input("æ¥­ç•Œåã‚’å…¥åŠ›", placeholder="ä¾‹: ç¾å®¹å®¤")

        st.divider()

        # ä½¿ã„æ–¹
        st.subheader("ğŸ“– ä½¿ã„æ–¹")
        st.markdown("""
        **æ­£èª¤ãƒã‚§ãƒƒã‚¯**
        1. Excelã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ ã€Œæ­£èª¤ãƒã‚§ãƒƒã‚¯é–‹å§‹ã€

        **åº—èˆ—èª¿æŸ»**
        1. èª¿æŸ»ãƒ¢ãƒ¼ãƒ‰é¸æŠ â†’ ä¼æ¥­å…¥åŠ› â†’ ã€Œåº—èˆ—èª¿æŸ»é–‹å§‹ã€

        **å±æ€§èª¿æŸ»** (NEW)
        1. ãƒ—ãƒªã‚»ãƒƒãƒˆé¸æŠ â†’ Excelå…¥åŠ› â†’ ã€Œå±æ€§èª¿æŸ»é–‹å§‹ã€

        **æ–°è¦å‚å…¥æ¤œå‡º** (NEW)
        1. æ—¢å­˜ãƒªã‚¹ãƒˆå…¥åŠ› â†’ ã€Œæ–°è¦å‚å…¥ã‚’æ¤œç´¢ã€

        **3æ®µéšãƒã‚§ãƒƒã‚¯** (NEW)
        1. ãƒ•ã‚§ãƒ¼ã‚ºé¸æŠ â†’ Excelå…¥åŠ› â†’ ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œ
        """)

    # ====================================
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢: æ©Ÿèƒ½é¸æŠ
    # ====================================
    st.subheader("ğŸ“Œ æ©Ÿèƒ½ã‚’é¸æŠ")

    function_type = st.radio(
        "æ©Ÿèƒ½ã‚¿ã‚¤ãƒ—",
        [
            "ğŸ” æ­£èª¤ãƒã‚§ãƒƒã‚¯",
            "ğŸª åº—èˆ—èª¿æŸ»",
            "ğŸ“Š å±æ€§èª¿æŸ»",
            "ğŸ†• æ–°è¦å‚å…¥æ¤œå‡º",
            "ğŸ“‹ 3æ®µéšãƒã‚§ãƒƒã‚¯",
        ],
        horizontal=True,
        label_visibility="collapsed",
    )

    st.divider()

    # ====================================
    # æ­£èª¤ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
    # ====================================
    if "å±æ€§èª¿æŸ»" in function_type:
        render_attribute_tab(provider=provider, industry=industry)

    elif "æ–°è¦å‚å…¥æ¤œå‡º" in function_type:
        render_newcomer_tab(provider=provider, industry=industry)

    elif "3æ®µéšãƒã‚§ãƒƒã‚¯" in function_type:
        render_workflow_tab(provider=provider, industry=industry)

    elif "æ­£èª¤ãƒã‚§ãƒƒã‚¯" in function_type:
        st.subheader("ğŸ“‚ Excelã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

        uploaded_file = st.file_uploader(
            "ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒªã‚¹ãƒˆExcelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["xlsx", "xls"],
            help="ã‚µãƒ¼ãƒ“ã‚¹å/ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼åã€å…¬å¼URL ã‚’å«ã‚€Excelãƒ•ã‚¡ã‚¤ãƒ«",
        )

        if uploaded_file:
            try:
                temp_dir = Path(tempfile.gettempdir()) / "player_list_checker"
                temp_dir.mkdir(parents=True, exist_ok=True)
                temp_path = temp_dir / uploaded_file.name
                temp_path.write_bytes(uploaded_file.getvalue())

                handler = ExcelHandler()
                players = handler.load(temp_path)
                st.session_state.players = players

                st.success(f"âœ… {len(players)}ä»¶ã®ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

                with st.expander("ğŸ“‹ æ¤œå‡ºã•ã‚ŒãŸåˆ—"):
                    cols = handler.get_column_names()
                    st.write(cols)

                with st.expander("ğŸ‘€ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­10ä»¶ï¼‰"):
                    preview_data = []
                    for p in players[:10]:
                        preview_data.append({
                            "ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼å": p.player_name,
                            "å…¬å¼URL": p.official_url[:50] + "..." if len(p.official_url) > 50 else p.official_url,
                            "é‹å–¶ä¼šç¤¾": p.company_name,
                        })
                    st.dataframe(pd.DataFrame(preview_data), use_container_width=True)

            except Exception as e:
                st.error(f"âŒ Excelã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
                st.session_state.players = []

        # ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        col1, col2 = st.columns([1, 3])
        with col1:
            check_limit = st.number_input(
                "ãƒã‚§ãƒƒã‚¯ä»¶æ•°",
                min_value=1,
                max_value=len(st.session_state.players) if st.session_state.players else 100,
                value=min(10, len(st.session_state.players)) if st.session_state.players else 10,
                help="APIã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚ã€æœ€åˆã¯å°‘æ•°ã§ãƒ†ã‚¹ãƒˆã—ã¦ãã ã•ã„",
            )

        with col2:
            run_button = st.button(
                "ğŸš€ æ­£èª¤ãƒã‚§ãƒƒã‚¯é–‹å§‹",
                type="primary",
                disabled=not st.session_state.players or st.session_state.is_running,
                use_container_width=True,
            )

        st.divider()

        if run_button:
            st.session_state.is_running = True

            progress_container = st.empty()
            status_container = st.empty()

            players_to_check = st.session_state.players[:check_limit]

            results = run_async(run_validation(
                players_to_check,
                industry=industry,
                provider=provider,
                progress_container=progress_container,
                status_container=status_container,
            ))

            st.session_state.validation_results = results
            st.session_state.is_running = False

        # çµæœè¡¨ç¤º
        if st.session_state.validation_results:
            results = st.session_state.validation_results

            display_validation_summary(results)

            st.divider()

            st.subheader("ğŸ“‹ è©³ç´°çµæœï¼ˆã‚¢ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«é †ï¼‰")
            display_validation_table(results)

            st.divider()

            st.subheader("ğŸ“¥ çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")

            col1, col2 = st.columns(2)

            with col1:
                excel_data = export_validation_results(results)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                st.download_button(
                    "ğŸ“¥ Excel ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒã‚§ãƒƒã‚¯çµæœï¼‰",
                    excel_data,
                    f"validation_report_{timestamp}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                )

            with col2:
                csv_data = []
                for result in results:
                    csv_data.append(result.to_dict())
                df_csv = pd.DataFrame(csv_data)
                csv_bytes = df_csv.to_csv(index=False).encode("utf-8-sig")

                st.download_button(
                    "ğŸ“¥ CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    csv_bytes,
                    f"validation_report_{timestamp}.csv",
                    "text/csv",
                    use_container_width=True,
                )

    # ====================================
    # åº—èˆ—èª¿æŸ»æ©Ÿèƒ½
    # ====================================
    elif "åº—èˆ—èª¿æŸ»" in function_type:
        st.subheader("ğŸ”§ èª¿æŸ»ãƒ¢ãƒ¼ãƒ‰é¸æŠ")

        mode_option = st.radio(
            "èª¿æŸ»ãƒ¢ãƒ¼ãƒ‰",
            [
                "ğŸ¤– AIèª¿æŸ»ï¼ˆé«˜é€Ÿï¼‰",
                "ğŸ”¬ AIèª¿æŸ»ï¼ˆç²¾å¯†ï¼‰",
                "ğŸ”— ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°",
                "ğŸ”„ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼ˆAI + ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è£œå®Œï¼‰",
            ],
            horizontal=True,
            label_visibility="collapsed",
        )

        # ãƒ¢ãƒ¼ãƒ‰å¤‰æ› & ãƒ¢ãƒ‡ãƒ«é¸æŠ
        ai_model = "sonar-pro"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        if "AIèª¿æŸ»ï¼ˆé«˜é€Ÿï¼‰" in mode_option:
            investigation_mode = InvestigationMode.AI
            ai_model = "sonar-pro"
        elif "AIèª¿æŸ»ï¼ˆç²¾å¯†ï¼‰" in mode_option:
            investigation_mode = InvestigationMode.AI
            ai_model = "sonar-deep-research"
            st.warning(
                "â³ **ç²¾å¯†ãƒ¢ãƒ¼ãƒ‰ï¼ˆsonar-deep-researchï¼‰ã®æ³¨æ„äº‹é …**\n\n"
                "- 1ä»¶ã‚ãŸã‚Šç´„5åˆ†ã‹ã‹ã‚Šã¾ã™\n"
                "- ã‚³ã‚¹ãƒˆãŒç´„10ã€œ50å€ã«ãªã‚Šã¾ã™\n"
                "- é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§ `?` ãŒå¤šã„å ´åˆã®ã¿æ¨å¥¨\n\n"
                "ã¾ãšã¯ã€ŒAIèª¿æŸ»ï¼ˆé«˜é€Ÿï¼‰ã€ã§ãƒ†ã‚¹ãƒˆã—ã¦ãã ã•ã„ã€‚"
            )
        elif "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°" in mode_option:
            investigation_mode = InvestigationMode.SCRAPING
        else:
            investigation_mode = InvestigationMode.HYBRID

        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ³¨æ„äº‹é …
        if investigation_mode in (InvestigationMode.SCRAPING, InvestigationMode.HYBRID):
            display_scraping_warning()

        st.divider()

        # å…¥åŠ›ã‚¿ãƒ–
        st.subheader("ğŸ“‚ ä¼æ¥­æƒ…å ±å…¥åŠ›")

        input_tab1, input_tab2 = st.tabs(["ğŸ“¤ Excelã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "âœï¸ ç›´æ¥å…¥åŠ›"])

        with input_tab1:
            uploaded_file = st.file_uploader(
                "ä¼æ¥­ãƒªã‚¹ãƒˆExcelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                type=["xlsx", "xls"],
                help="ä¼æ¥­åã€å…¬å¼URL ã‚’å«ã‚€Excelãƒ•ã‚¡ã‚¤ãƒ«",
                key="store_excel_upload",
            )

            if uploaded_file:
                try:
                    temp_dir = Path(tempfile.gettempdir()) / "store_investigator"
                    temp_dir.mkdir(parents=True, exist_ok=True)
                    temp_path = temp_dir / uploaded_file.name
                    temp_path.write_bytes(uploaded_file.getvalue())

                    handler = ExcelHandler()
                    players = handler.load(temp_path)

                    # ä¼æ¥­æƒ…å ±ã«å¤‰æ›
                    companies = []
                    for p in players:
                        companies.append({
                            "company_name": p.company_name or p.player_name,
                            "official_url": p.official_url,
                            "industry": industry,
                        })

                    st.session_state.store_companies = companies
                    st.success(f"âœ… {len(companies)}ä»¶ã®ä¼æ¥­ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

                    with st.expander("ğŸ‘€ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­10ä»¶ï¼‰"):
                        preview_data = []
                        for c in companies[:10]:
                            preview_data.append({
                                "ä¼æ¥­å": c["company_name"],
                                "å…¬å¼URL": c["official_url"][:50] + "..." if len(c["official_url"]) > 50 else c["official_url"],
                            })
                        st.dataframe(pd.DataFrame(preview_data), use_container_width=True)

                except Exception as e:
                    st.error(f"âŒ Excelã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
                    st.session_state.store_companies = []

        with input_tab2:
            st.markdown("**ä¼æ¥­æƒ…å ±ã‚’ç›´æ¥å…¥åŠ›**ï¼ˆ1è¡Œ1ä¼æ¥­ï¼‰")

            input_text = st.text_area(
                "ä¼æ¥­å,å…¬å¼URL ã®å½¢å¼ã§å…¥åŠ›",
                placeholder="ã‚¹ã‚¿ãƒ¼ãƒãƒƒã‚¯ã‚¹,https://www.starbucks.co.jp/\nãƒ‰ãƒˆãƒ¼ãƒ«,https://www.doutor.co.jp/",
                height=150,
            )

            if st.button("ğŸ“ å…¥åŠ›å†…å®¹ã‚’åæ˜ ", key="apply_direct_input"):
                companies = []
                for line in input_text.strip().split("\n"):
                    if not line.strip():
                        continue
                    parts = line.split(",")
                    company_name = parts[0].strip()
                    official_url = parts[1].strip() if len(parts) > 1 else ""

                    companies.append({
                        "company_name": company_name,
                        "official_url": official_url,
                        "industry": industry,
                    })

                if companies:
                    st.session_state.store_companies = companies
                    st.success(f"âœ… {len(companies)}ä»¶ã®ä¼æ¥­ã‚’ç™»éŒ²ã—ã¾ã—ãŸ")
                else:
                    st.warning("âš ï¸ ä¼æ¥­æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        st.divider()

        # èª¿æŸ»å®Ÿè¡Œ
        col1, col2 = st.columns([1, 3])
        with col1:
            check_limit = st.number_input(
                "èª¿æŸ»ä»¶æ•°",
                min_value=1,
                max_value=len(st.session_state.store_companies) if st.session_state.store_companies else 100,
                value=min(5, len(st.session_state.store_companies)) if st.session_state.store_companies else 5,
                help="APIã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚ã€æœ€åˆã¯å°‘æ•°ã§ãƒ†ã‚¹ãƒˆã—ã¦ãã ã•ã„",
                key="store_check_limit",
            )

        with col2:
            run_button = st.button(
                "ğŸš€ åº—èˆ—èª¿æŸ»é–‹å§‹",
                type="primary",
                disabled=not st.session_state.store_companies or st.session_state.is_running,
                use_container_width=True,
                key="store_run_button",
            )

        st.divider()

        if run_button:
            st.session_state.is_running = True

            progress_container = st.empty()
            status_container = st.empty()

            companies_to_check = st.session_state.store_companies[:check_limit]

            results = run_async(run_store_investigation(
                companies_to_check,
                mode=investigation_mode,
                provider=provider,
                progress_container=progress_container,
                status_container=status_container,
                ai_model=ai_model,
            ))

            st.session_state.store_results = results
            st.session_state.is_running = False

        # çµæœè¡¨ç¤º
        if st.session_state.store_results:
            results = st.session_state.store_results

            display_store_summary(results)

            st.divider()

            st.subheader("ğŸ“‹ è©³ç´°çµæœ")
            display_store_table(results)

            st.divider()

            st.subheader("ğŸ“¥ çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")

            col1, col2 = st.columns(2)

            with col1:
                excel_data = export_store_results(results)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                st.download_button(
                    "ğŸ“¥ Excel ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆåº—èˆ—èª¿æŸ»çµæœï¼‰",
                    excel_data,
                    f"store_investigation_{timestamp}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                )

            with col2:
                csv_data = []
                for result in results:
                    csv_data.append(result.to_dict())
                df_csv = pd.DataFrame(csv_data)
                csv_bytes = df_csv.to_csv(index=False).encode("utf-8-sig")

                st.download_button(
                    "ğŸ“¥ CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    csv_bytes,
                    f"store_investigation_{timestamp}.csv",
                    "text/csv",
                    use_container_width=True,
                )

            # è©³ç´°è¡¨ç¤º
            st.divider()
            st.subheader("ğŸ“ ä¼æ¥­åˆ¥è©³ç´°")

            for result in results:
                stores_display = result.total_stores or 0
                conf_display = (result.confidence or 0) * 100
                with st.expander(f"{'âš ï¸' if result.needs_verification else 'âœ…'} {result.company_name} - {stores_display}åº—èˆ—"):
                    col1, col2 = st.columns(2)

                    with col1:
                        st.write("**åŸºæœ¬æƒ…å ±**")
                        st.write(f"- ç·åº—èˆ—æ•°: {stores_display}")
                        if result.direct_stores is not None:
                            st.write(f"- ç›´å–¶åº—: {result.direct_stores}")
                        if result.franchise_stores is not None:
                            st.write(f"- FCåº—: {result.franchise_stores}")
                        st.write(f"- èª¿æŸ»ãƒ¢ãƒ¼ãƒ‰: {result.investigation_mode}")
                        st.write(f"- ä¿¡é ¼åº¦: {conf_display:.0f}%")

                    with col2:
                        st.write("**æƒ…å ±ã‚½ãƒ¼ã‚¹**")
                        if result.source_urls:
                            for url in result.source_urls:
                                st.write(f"- {url}")
                        else:
                            st.write("- ãªã—")

                    if result.prefecture_distribution:
                        st.write("**éƒ½é“åºœçœŒåˆ¥åº—èˆ—æ•°**")
                        pref_df = pd.DataFrame([
                            {"éƒ½é“åºœçœŒ": k, "åº—èˆ—æ•°": v}
                            for k, v in result.prefecture_distribution.items()
                        ]).sort_values("åº—èˆ—æ•°", ascending=False)
                        st.dataframe(pref_df, use_container_width=True, height=200)

                    if result.notes:
                        st.write("**å‚™è€ƒ**")
                        st.write(result.notes)


if __name__ == "__main__":
    main()
